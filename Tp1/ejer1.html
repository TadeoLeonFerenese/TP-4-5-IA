<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8">
  <title>Inteligencia Artificial</title>
  <link rel="stylesheet" href="styles.css">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Lora:ital,wght@0,400..700;1,400..700&family=Oswald:wght@200..700&family=Source+Code+Pro:ital,wght@0,200..900;1,200..900&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Bebas+Neue&family=Lora:ital,wght@0,400..700;1,400..700&family=Oswald:wght@200..700&family=Pixelify+Sans:wght@400..700&family=Source+Code+Pro:ital,wght@0,200..900;1,200..900&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Nanum+Gothic+Coding&family=Play:wght@400;700&display=swap" rel="stylesheet">
</head>
<body>
  <header>
    <h1>Backpropagation</h1>
    <img src="img/Logo2.png" alt="Logo" class="logo-derecha">
  </header>
  <div class="container">
    <aside>
      <h2>Indice</h2>
      <ul>
        <li><a href="index.html">Back-Propagation</a></li>
        <li><a href="segunda.html">Red Neuronal Convolucional</a></li>

    </aside>
    <main>
      <article>
        <h2>¿Que es back-propagation?</h2>
         
        <br />
        <p class="p1"> La retropropagación es un algoritmo fundamental utilizado en el entrenamiento de redes neuronales artificiales. Permite que la red aprenda de los errores cometidos durante las predicciones, ajustando los pesos de las conexiones en función del error de salida. Aquí están los componentes y procesos clave involucrados en la retropropagación:<br>

            <br> <b>Forward Pass:</b>  El proceso comienza con un paso adelante, donde se alimentan datos de entrada a la red y se realizan predicciones basadas en los pesos actuales. La salida se compara con los valores reales para calcular el error utilizando una función de pérdida. 
            
            
            <br><br> <b>Error calculation:</b> El error se cuantifica utilizando una función de pérdida, como el Error Cuadrático Medio (MSE) o la Pérdida de Entropía Cruzada, dependiendo del tipo de problema (regresión o clasificación).
            
            <br><br> 
            <b>Backward Pass:</b> En esta fase, el algoritmo calcula el gradiente de la función de pérdida con respecto a cada peso aplicando la regla de la cadena del cálculo. Esto implica:
            Calcular el gradiente de la pérdida con respecto a la salida.
            Propagar este gradiente hacia atrás a través de las capas de la red para calcular los gradientes para cada peso.

            <br><br><b>Weight Update:</b> Una vez que se calculan los gradientes, los pesos se actualizan utilizando un algoritmo de optimización.
            
            
            </p>
            
            
      </article>
      <h4>Imagen de referencia</h4>
      <img width="560" height="315" src="https://serokell.io/files/a0/a05ov1m.Backpropagation_in_NN_pic1.jpg" alt="Imagen 2"> <br>
      <article>
        <br>
        <h3>Importancia

        </h3>
        <p class="p1">
          <b>Aprender de los Errores:</b> La retropropagación permite que las redes neuronales ajusten sus parámetros basándose en errores, mejorando su rendimiento con el tiempo.
            
            <br><br><b>Eficiencia:</b> El algoritmo calcula eficientemente los gradientes para todos los pesos en un solo paso hacia atrás, lo que lo hace factible para redes profundas.
            
            <br><br><b>Fundamento para el Aprendizaje Profundo:</b> La retropropagación es crucial para entrenar modelos de aprendizaje profundo, permitiéndoles aprender patrones complejos a partir de grandes conjuntos de datos.
            

            </p>
            <h4>Video para reforzar contenido</h4>
            <iframe width="868" height="488" src="https://www.youtube.com/embed/boP3O89rErA" title="Redes Neuronales - Backpropagation" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

            
    </article>
    
    </main>
  </div>
  <footer>
    <p>Derechos de autor © 2024 - Unab - Inteligencia Artificial</p>
  </footer>
</body>
</html>